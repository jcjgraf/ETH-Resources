%! TEX root = ./main.tex

\section{Diskrete Zufallsvariablen und Verteilungen}
\subsection{Grundbegriffe}
\begin{itemize}
    \ides{Zufallsvariable (ZV):} $X: \Omega \to \R$
        \begin{itemize}
            \item Falls $\Sigam$ endlich/abzählbar dann ist Wertebereich $W(X)$ auch endlich
        \end{itemize}
    \ides{Verteilungsfunktion (VF)} von $x$: $f_X : \R \to [0,1]$
        \begin{itemize}
            \item $F_X(t) := P[X \le t] := P[\{\omega \mid X(\omega) \le t\}]$
        \end{itemize}
    \ides{Gewichtsfunktion:} $p_X: \mc{W}(X) \to [0,1]$
        \begin{itemize}
            \item $p_X(x_k) := P[X = x_k] = P[\{\omega \mid X(\omega) = x_k\}], k = 1, 2, \dots$
        \end{itemize}
\end{itemize}

\subsubsection{Erwartungswert}
\begin{itemize}
    \ides{Erwartungswert (EW):} $E[X] := \sum_{x_k \in \mc{W}(X)} x_k p_X(x_k)$
        \begin{itemize}
            \item Definiert falls $\sum_{x_k \in \mc{W}(X)} |x_k| p_X(x_k) < \infty$
        \end{itemize}
    \item Sei $Y = g(X), g: \R \to \R$, dann: $E[Y] = E[g(X)] = \sum_{x_k \in \mc{W}(X)} g(x_k) p_X(x_k)$
    \item $X$, $Y$ ZV und EW existieren, dann:
        \begin{itemize}
            \ides{Monotonie:} $\forall \omega \ X(\omega) \le Y(\omega) \implies E[X] \le E[Y]$
            \ides{Linearität:} Für bel. $a,b \in \R$ gilt $E[aX + b] = a E[X] + b$
            \item Falls $\mc{W}(X) = \N_0$ so gilt $E[X] = \sum_{j=1}^{\infty} P[X \ge j] = \sum_{l=0}^{\infty} P[X > l]$
        \end{itemize}
\end{itemize}

\subsubsection{Varianz}
\begin{itemize}
    \ides{Varianz:} $Var[X] := E[(X - E[X])^2]$
        \begin{itemize}
            \item Definiert falls $E[X^2] < \infty$
            \ides{Standardabweichung:} $\sigma(X) := \sqrt{Var[X]}$
            \item $Var[X] = \sum_{x_k \in \mc{W}(X)} (x_k - E[X])^2 p_X(x_k)$
        \end{itemize}
    \item Seien $Y = aX + b$, dann:
        \begin{itemize}
            \item $Var[X] = E[X^2] - (E[X])^2$
            \item $Var[Y] = Var[aX + b] = a^2 Var[X]$
        \end{itemize}
    \ides{Kovarianz:} $Cov(X,Y) := E[XY] - E[X] E[Y] = E[(X - E[X])(Y - E[Y])]$
    \item $Var[X + Y] = Var[X] + Var[Y] + 2 Cov(X, Y)$
    \item $Cov(X, X) = Var[X]$
    \ides{Unkorreliert:} Falls $Cov(X, Y) = 0$
    \ides{Paarweise Unkorreliert:} Falls alle Paare $X_i, X_j$ mit $i \neq j$ unkorreliert sind
\end{itemize}

\subsection{Mehrere Zufallsvariable}
\begin{itemize}
    \ides{Gemeinsame Verteilungsfunktion:} $F: \R^n \to [0,1]$ seien $X_1, \dots, X_n$ ZV, dann:\\ $F(x_1, \dots, x_n) := P[X_1 \le x_1, \dots, X_n \le x_n]$
    \ides{Gemeinsame Gewichtsfunktion:} $p: \R^n \to [0,1]$ seien $X_1, \dots, X_n$ diskrete ZV, dann:\\ $p(x_1, \dots, x_n) := P[X_1 = x_1, \dots, X_n = x_n]$
    \ides{Randverteilung:} Haben $X$ und $Y$ gemeinsame VF $F$, dann ist $F_X: \R \to [0,1]$ die Randverteilung von $X$\\ $F_{X(X)} := P[X \le x] = P[X \le x, Y < \infty] = \lim_{y \to \infty} F(x, y)$
    \ides{Gewichtsfunktion der Randverteilung:} $p_X: \mc{W}(X) \to [0,1]$ von $X$ ist $p_x(x) = P[X = x] = \sum_{y_j \in \mc{W}(Y)} P[X = x, Y = y_j] = \sum_{y_j \in \mc{W}(Y)} p(x, y_j)$
\item ZV $X_1, \dots, X_n$ heissen unabhängig, falls $F(x_1, \dots, x_n) = F_{X_1}(x_1) \dots F_{X_n}(x_n)$ oder falls ZV diskret $p(x_1, \dots, x_n) = p_{X_1}(x_1) \dots p_{X_n}(x_n)$
\end{itemize}

\subsection{Funktionen von mehreren ZV}
\begin{itemize}
    \item Seien $X_1, \dots X_n$ diskrete ZV und $Y = g(X_1, \dots, X_n), g: \R^n \to \R$, dann ist $Y$ eine diskret ZV
    \item Seien $X_1, \dots X_n$ diskret ZV mit endlichen EW. Sei $Y = a + \sum_{l=1}^{n} b_l X_l$. Dann ist $E[Y] = a + \sum_{l=1}^{n} b_l E[X_l]$
    \ides{Summenformel für Varianzen:}\\ $Var [\sum_{i=1}^{n} X_i] = \sum_{i=1}^{n} Var[X_i] + 2 \sum_{i<j} Cov(X_i, X_j)$
    \item Falls $X_1, \dots, X_n$ paarweise unkorreliert dann $Var[\sum_{i=1}^{n} X_i] = \sum_{i=1}^{n} Var[X_i]$
    \item Seien $X_1, \dots, X_n$ diskret ZV mit endlichen EW. Falls $X_1, \dots, X_n$ unabhängig: $E[\Pi_{i=1}^{n} X_i] = \Pi_{i=1}^{n} E[X_i]$
    \item unabhängig $\implies$ paarweise unabhängig $\implies$ unkorreliert
\end{itemize}

\subsection{Summe von zwei ZV}
\begin{itemize}
    \item Seien $X, Y$ diskret ZV mit gemeinsamer GF $p(x, y)$, dann ist $Z = X + Y$ diskret. GF von $Z$: $p_Z(z) = P[Z = z] = \sum_{x_k \in \mc{W}(X)} P[X = x_k, Y = z - x_k] = \sum_{x_k \in \mc{W}(X)} p(x_k, z - x_k)$
    \item Sind $X, Y$ unabhängig ZV, so ist $p(x, y) = p_X(x) p_Y(y)$ und damit: $p_Z(z) = \sum_{x_k \in \mc{W}(X)} p_x(x_k) p_Y(z - x_k)$
\end{itemize}

\subsection{Bedingte Verteilungen}
