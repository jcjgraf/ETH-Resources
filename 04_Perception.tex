%! TEX root = ./main.tex

\section{Perception}
\subsection{Sensors}
\subsection{Computer Vision}
\subsubsection{Camera Model}
\begin{itemize}
    \ides{Pinhole Model:}
        \begin{itemize*}
            \item Black box with single hole
            \item Beam of rays enter through the \textbf{Optical Center/Center of Projection C}
            \item Inverted image is projected onto the \textbf{Image Plane}
        \end{itemize*}
    \ides{Converging Lens:}
        \begin{itemize*}
            \item Focuses multiple rays from the same point on the object to the same point on the image plane
            \item All rays parallel to the \textbf{optical axis} converge at the \textbf{focal point}
            \item Rays passing through the \textbf{optical center} are not diverged
        \end{itemize*}
    \ides{Thin Lens equation:} $\frac{1}{f} = \frac{1}{z} + \frac{1}{e}$
    \\ \includegraphics[width=\linewidth]{./Figures/04_ThinLensEquation.png}
    \ides{Pinhole Approximation:} $z \gg f \implies f \approx e$
        \begin{itemize}
            \item I.e. lens is approximated as pinhole at distance $f$ from image plane
            \item If follows that $B = \frac{f}{z}B$
        \end{itemize}
\end{itemize}

\subsubsection{Perspective Camera}
\begin{itemize}
    \item Image plane represented in front of $C$
    \item Camera measures angles and not distances
    \item Project pt $P_W = (x,y,z)$ onto $p_C = (u,v)$ on the image plane
    \ides{Perspective Equations:}\\
        \begin{itemize*}
            \item $x = f \frac{X_c}{Z_C}$
            \item $y = f \frac{Y_c}{Z_C}$
        \end{itemize*}\\
        \begin{itemize*}
            \item $u = u_0 + k x$
            \item $v = v_0 + k y$
            \ides{Scale factor $k$} $[\text{pixels}/\text{meter}]$
        \end{itemize*}
        \begin{itemize}
            \item $\implies \tilde p =
                \begin{bmatrix}
                    \lambda u\\
                    \lambda v\\
                    \lambda
                \end{bmatrix} =
                \underbrace{
                \begin{bmatrix}
                    kf & 0 & u_0\\
                    0 & kf & v_0\\
                    0 & 0 & 1
                \end{bmatrix}}_{K}
                \begin{bmatrix}
                    X_C\\
                    Y_C\\
                    Z_C
                \end{bmatrix}$
        \end{itemize}
    \ides{Intrinsic Parameter $K$:} depending on camera
    \item Rigid Body transformation\\
        $\begin{bmatrix}
            X_C\\
            Y_C\\
            Z_C
        \end{bmatrix}=
        \underbrace{
        \begin{bmatrix}
            r_{11}  & r_{12} & r_{13}\\
            r_{21}  & r_{22} & r_{23}\\
            r_{31}  & r_{32} & r_{33}\\
        \end{bmatrix}}_{R}
        \begin{bmatrix}
        X_W\\
        Y_W\\
        Z_W
        \end{bmatrix} +
        \underbrace{
        \begin{bmatrix}
            t_1\\
            t_2\\
            t_3
        \end{bmatrix}}_{T} = [R \mid T]
        \begin{bmatrix}
            X_W\\
            Y_W\\
            Z_W\\
            1
        \end{bmatrix}$
    \ides{Extrinsic Parameter $[R \mid T]$:} depending on transformation
    \ides{Perspective Projection:} $K[R \mid T]$
    \item $\implies \tilde p =
        \begin{bmatrix}
            \lambda u\\
            \lambda v\\
            \lambda
        \end{bmatrix} = K[R \mid T]
        \begin{bmatrix}
            X_W\\
            Y_W\\
            Z_W\\
            1
        \end{bmatrix}$
    \ides{Barrel Distortion}
        \begin{itemize}
            \item Straight lines get bend
            \ides{Barrel Distortion:} Image gets ``round''
            \ides{Pincusion Distortion:} Corners pulled out
            \item Model:
                $\begin{bmatrix}
                    u_d\\
                    v_d
                \end{bmatrix} = (1 + k_1 r^2)
                \begin{bmatrix}
                    u - u_0\\
                    v - v_0
                \end{bmatrix} +
                \begin{bmatrix}
                    u_0\\
                    v_0
                \end{bmatrix}$
                \begin{itemize}
                    \ides{Distortion Parameter $\mathbf{k_1}$:} Intrinsic parameter
                    \item $r^2 = (u - u_0)^2 + (v - v_0)^2$
                \end{itemize}
        \end{itemize}
\end{itemize}

\subsubsection{Omnidirectional Camera}
\begin{itemize}
    \ides{Dioptric:}
        \begin{itemize*}
            \item System of lenses
            \item $\sim 180^\circ$ FOV
        \end{itemize*}
    \ides{Catadioptric:}
        \begin{itemize*}
            \item Combination of lens and mirrors
            \item $> 180^\circ$ FOV
            \item Greatly distorted (can be removed depending on mirror)
        \end{itemize*}
        \begin{itemize}
            \ides{Central Camera:} Mirror shaped that all incoming rays have same \textit{single effective viewpoint}
                \begin{itemize}
                    \ides Correct mirror placement is important
                    \ipro Unwarping into perspective image possible
                    \ipro Can convert points in the image to spherical vectors
                    \ipro Can apply standard algorithms
                \end{itemize}
        \end{itemize}
    \ides{Polydioptric:}
        \begin{itemize*}
            \item Multiple cameras
            \item $\sim 360^\circ$ FOV
        \end{itemize*}
\end{itemize}

\subsubsection{Camera Calibration}
\begin{itemize}
    \item Determine intrinsic (and extrinsic) camera parameters
    \item Done using least-square method
\end{itemize}

\subsubsection{Stereo Vision}
\begin{itemize}
    \item Obtain depth information from two cameras with know relative position
    \item Cameras need to be calibrated
    \item Calculating depth $Z_P$ of point $P_W$ (distance to $P_W$)
    \ides{Baseline $\mathbf{b}$:} Distance between the two cameras
    \ides{Disparity:} Difference in image location of the projection of a 3D point on the two image panes: $u_l - u_r$
    \item Two identical cameras aligned on $x$
        \begin{itemize}
            \item $Z_P = \frac{bf}{u_l - u_r}$
        \end{itemize}
    \item Two identical cameras in different Coordinate Systems
        \begin{itemize}
            \item $C_r$ is a rigid body transformation of $C_l$\\
            \item Triangulation
            \begin{itemize*}
                \item $\tilde p_l = \lambda_l
                    \begin{bmatrix}
                        u_l\\
                        v_l\\
                        1
                    \end{bmatrix} = K_l
                    \begin{bmatrix}
                        X_W\\
                        Y_W\\
                        Z_W
                    \end{bmatrix}$
                \item $\tilde p_r = \lambda_r
                    \begin{bmatrix}
                        u_r\\
                        v_r\\
                        1
                    \end{bmatrix} = K_r R
                    \begin{bmatrix}
                        X_W\\
                        Y_W\\
                        Z_W
                    \end{bmatrix} + T$
            \end{itemize*}
        \end{itemize}
    \ides{Disparity Map}
        \begin{itemize}
            \item Compute disparity for corresponding points of every pixel
            \item Can compute the depth from it and reconstruct 3D scene
        \end{itemize}
\end{itemize}

\subsubsection{Correspondence Search}
\begin{itemize}
    \item Identify corresponding points in two images of the same scene
    \item Measure similarity of two pts using a similarity measurement
    \ides{Epipolar Plane:} Spanned by $C_l$, $C_r$ and some pt $P_W$
    \ides{Epipolar Line:} Projection of the ray from one camera through points in the other camera
    \ides{Epipole:} Projection of other camera in image plane
        \begin{itemize*}
            \item All epipolar lines go through it
        \end{itemize*}
    \ides{Epipolar Constraint:} Correspond of pt of left images lies on the epipolar line of the right image
    \ides{Epipolar Rectification:} Transform both images to make epipolar lines collinear and parallel:
        \begin{itemize*}
            \item[1)] Remove radial distortion
            \item[2)] \textbf{Warping:} Reprojection of both images to same plane
        \end{itemize*}
\end{itemize}

\subsubsection{Structure from Motion (SfM)}
\begin{itemize}
    \item Given corresponding image points $\{(u_1^i, v_1^i), (u_2^i, v_2^i)\}$, recover:
        \begin{itemize*}
            \item 3D location $P_i$ of all $n$ pts
            \item Relative pose of right camera $R, T$
            \item Camera intrinsic $K$ (optionally)
        \end{itemize*}
    \item Assume $K$ is known
    \ides{Knowns:} $4n$: $n$ correspondences
    \ides{Unknowns:} $5 + 3n$: rotation ($3$), translation ($2$, since scale cannot be recovered), $n$ 3D pts ($3n$)
    \item Solution exists iff $4n \ge 5 + 3n \implies n \ge 5$
    \ides{Crossp.:} $a \times b =
        \begin{bmatrix}
            0 & -a_z & a_y\\
            a_z & 0 & -a_x\\
            -a_y & a_x & 0
        \end{bmatrix}
        \begin{bmatrix}
            b_x\\
            b_y\\
            b_z
        \end{bmatrix} = [a]_\times b$
    \ides{Epipolar Constraint:} $p_2^T E p_1 = 0$
    \ides{Essential Matrix:} $E = [T]_\times R$
        \begin{itemize}
            \item Computed with $\ge 5$ correspondences
            \item Can be decomposed into $R$ and $T$
        \end{itemize}
    \ides{Normalized Img Coordinates:} $p = [\bar u, \bar v, 1]^\transpose = K^{-1}[u, v, 1]^\transpose$
    \ides{8-pt Algorithm}
        \begin{itemize*}
            \item Algorithm to compute essential matrix
            \item Uses $\ge 8$ pts
        \end{itemize*}
        \begin{itemize}
            \item $p_2^\transpose E p_1 = [\bar u_2, \bar v_2, 1]
                \begin{bmatrix}
                    e_11 & e_12 & e_13\\
                    e_21 & e_22 & e_23\\
                    e_31 & e_32 & e_33
                \end{bmatrix}
                \begin{bmatrix}
                    \bar u_1\\
                    \bar v_1\\
                    1
                \end{bmatrix} = 0$
            \item $\underbrace{[u_2u_1, u_2v_1, u_2, v_2u_1, v_2v_1, v_2, u_1, v_1, 1]}_{Q: \text{known}}\underbrace{[e_{11}, e_{12}, \dots, e_{33}]}_{\text{unknown}} = 0$
            \item For $8$ non-coplanar pts, unique solution is given by the EV of $Q$ corresponding to the smallest Eigenvalue
        \end{itemize}
\end{itemize}

\subsubsection{Image Filtering}
\begin{itemize}
    \ides{Linear:} Replace each pixel by a linear combination of its neighbours
    \ides{Shift-Invariant:} Same operation is performed on every point on the image
    \ides{Filter $\mathbf{H}$:} aka. \textit{kernel, mask, window}
    \ides{Boundaries:} Need to handle specially:
        \begin{itemize*}
            \item Ignore
            \item Zero padding
            \item Pad with edge value
            \item Mirror boundary
            \item Wrap around from other side
        \end{itemize*}
    \ides{Normalization:} Prevent img from getting brighter/darker
    \ides{Correlation:} $J(x) = F \circ I(x,y) = \sum_{i=-N}^N \sum_{j=-M}^M F(i,j) I(x + i, y + j)$
        \begin{itemize}
            \item Not associative
        \end{itemize}
    \ides{Convolution:} $J(x) = F \ast I(x,y) = \sum_{i=-N}^N \sum_{j=-M}^M F(i,j) I(x - i, y - j)$
        \begin{itemize}
            \item Equivalent to correlation except that the filter is flipped before correlating
            \item Same result to correlation if the filter is symmetric
            \item Is associative: $F \ast (G \ast I) = (F \ast G) \ast I$
        \end{itemize}
    \ides{Correlation Cost: (per pixel)}
        \begin{itemize}
            \ides{2D:}
                \begin{itemize*}
                    \ides{Mult.:} $(2N + 1)^2$
                    \ides{Add.:} $(2N - 1)^2 - 1$
                \end{itemize*}
            \ides{$\mathbf{2 \times 1D}$:}
                \begin{itemize*}
                    \ides{Mult.:} $2(2N + 1)$
                    \ides{Add.:} $4N$
                \end{itemize*}
            \ides{$\mathbf{2 \times 1D}$ with const.:}
                \begin{itemize*}
                    \ides{Mult.:} $1$
                    \ides{Add.:} $4N$
                \end{itemize*}
        \end{itemize}
    \ides{Derivation:} $J(x) = \frac{I(x+1)-I(x-1)}{2}$
    \ides{Smoothing:}
        \begin{itemize}
            \item For blurring or noise detection
            \ides{1D Gaussian:} $G_\sigma(x) = \frac{1}{\sigma \sqrt{2 \pi}} \mathrm e^{-\frac{x^2}{2 \sigma^2}}$
            \ides{2D Gaussian:} $G_\sigma(x, y) = \frac{1}{2 \pi \sigma^2} \mathrm e^{-\frac{x^2 + y^2}{2 \sigma ^2}} = g_\sigma(x) \cdot g_\sigma(y) =
                \tfrac{1}{\sigma \sqrt{2\pi}} \mathrm e^{\frac{-x^2}{2\sigma^2}}
                \cdot
                \tfrac{1}{\sigma \sqrt{2\pi}} \mathrm e^{\frac{-y^2}{2\sigma^2}}$
                \begin{itemize}
                    \item Is separable
                \end{itemize}
        \end{itemize}
    \ides{Similarity Measure}
        \begin{itemize}
            \ides{Sum of Square Diff.:} $\mathrm{SSD}(x) =
                \sum_i (F(i) - I(x+i))^2 =
                \sum_i F(i)^2 + \sum_i I(x+i)^2 - 2 \sum_i (F(i) I(x+i))$
            \ides{Normalized Cross Correlation:} $\mathrm{NCC} =
                \frac{\sum_i (F(i)I(x + i))}
                {\sqrt{\sum_i F(i)^2} \sqrt{\sum_i I(x+i)^2}}$
            \ides{Zero-Mean Normalized Cross Correlation (ZNCC)}: Invariant to local average intensity. Maximize: $\mathrm{ZNCC}(x) =
                \frac{\sum_i (F(i)- \mu_F)(I(x + i) - \mu_{I_x})}
                {
                    \sqrt{\sum_i (F(i) - \mu_F)^2}
                    \sqrt{\sum_i (I(x+i) - \mu_{I_x})^2}
                }$
                \begin{itemize*}
                    \item $\mu_F = \frac{\sum_i F(i)}{2N + 1}$
                    \item $\mu_{I_x} = \frac{\sum_i I(x+i)}{2N + 1}$
                \end{itemize*}
        \end{itemize}
    \ides{Template Matching:} Use template as filter and apply similarity measure
    \ides{Edge Detection:}
        \begin{itemize*}
            \item[1)] Noise reduction
            \item[2)] Gradient $S^\prime = (G_\sigma \ast I)^\prime = G_\sigma^\prime \ast I$
            \item[3)] Thresholding
            \item[4)] Non-maximal suppression
        \end{itemize*}
        \begin{itemize}
            \ides{Derivation of Gaussian:} $G_\sigma^\prime(x, y) = \frac{\partial G_\sigma(x, y)}{\partial x} + \frac{\partial G_\sigma(x, y)}{\partial y}$
                \begin{itemize*}
                    \item Edges at min/max
                \end{itemize*}
            \ides{Laplacian of Gaussian:} $\mathrm{LoG} = G_\sigma^{\prime\prime}(x, y) = \frac{\partial^2 G_\sigma(x, y)}{\partial x^2} + \frac{\partial^2 G_\sigma(x, y)}{\partial y^2}$
                \begin{itemize*}
                    \item Edges at zero crossing
                \end{itemize*}
        \end{itemize}
\end{itemize}

\subsubsection{Point Features}
\begin{itemize}
    \ides{Harris Corner Detection:} Patch at $(x,y)$ of size $P$ has great difference to all surrounding patches $(x + \Delta x, y + \Delta y)$
        \begin{itemize}
            \item $\mathrm{SSD}(\Delta x, \Delta y) = \sum_{x,y \in P}(I(x,y) - I(x + \Delta x, y + \Delta y))^2$
            \item $\Rightarrow \mathrm{SSD}(\Delta x, \Delta y) \approx \sum_{x,y \in P}(I_x(x,y)x - I_y(x, y)y)^2$
                \\ \begin{itemize*}
                    \item $I_{x} = \frac{\partial I(x,y)}{\partial x}$
                    \item $I_{y} = \frac{\partial I(x,y)}{\partial y}$
                    \item Using first-order Taylor approx
                \end{itemize*}
            \item $\Rightarrow \mathrm{SSD}(\Delta x, \Delta y) \approx [\Delta x, \Delta y]M[\Delta x, \Delta y]^\transpose$
                \\ \begin{itemize*}
                    \item $M = \sum_{x,y \in P}
\begin{bmatrix}
    I_x^2 & I_xI_y\\
    I_xI_y & I_y^2
\end{bmatrix} = R^{-1}
\begin{bmatrix}
    \lambda_1 & 0\\
    0 & \lambda_2
\end{bmatrix} R$
                \end{itemize*}
            \item \begin{itemize*}
                \ides{$\mathbf{\lambda_1, \lambda_2}$ small:} Flat region
                \ides{$\mathbf{\lambda_1 >> \lambda_2}$:} Edge
                \ides{$\mathbf{\lambda_1 << \lambda_2}$:} Edge
                \ides{$\mathbf{\lambda_1, \lambda_2}$ large:} Corner
            \end{itemize*}
            \ides{Cornerness Function:} $C = \text{det} - \kappa \ \text{trace}^2(M)$
                \\ \begin{itemize*}
                    \item Extract local minima
                    \item Used since calculating eigenvalues is expensive
                    \item $\kappa$ is magic number
                \end{itemize*}
            \ides{Invariant to:}
                \begin{itemize*}
                    \item Rotation
                    \item Linear intensity change
                \end{itemize*}
            \ides{Not invariant to:} Scale change
        \end{itemize}
    \ides{Scale Invariant Feature Transform (SIFT) Features:}
        \begin{itemize}
            \item Detect blobs
            \item Assigns each keypoint a orientation and descriptor
            \ides{Keypoint Detection:}
                \begin{itemize*}
                    \item[1)] Downscale image multiple times
                    \item[2)] Gaussian blur each at different rates
                    \item[3)] Calculate \textit{Difference of Gaussian (DoG)} (subtract successive smoothed images)
                    \item[4)] Find keypoints (local extrema in the DoG)
                \end{itemize*}
            \ides{Keypoint Orientation:}
                \begin{itemize*}
                    \item[1)] Generate gradient orientation histogram for each keypoint
                    \item[2)] Orientation is value of highest peak in histogram
                \end{itemize*}
            \ides{Keypoint Descriptor:}
                \begin{itemize*}
                    \item[1)] Divide neighbourhood into $4 \times 4$ regions
                    \item[2)] Compute orientation histograms along $8$ orientations
                    \item[3)] Concatenate $4 \times 4 \times 8 = 128$ values in vector
                \end{itemize*}
            \ipro High robustness
            \ipro Invariant to rotation
        \end{itemize}
    \ides{Features from Accelerated Segment Test (FAST) Detector:}
        \begin{itemize*}
            \item Detects corners
            \item Look at $16$ pixels around target pixel
            \item If they are all significantly darker/brighter, we have a FAST corner
            \ipro Fast
            \icon Not robust against noise
        \end{itemize*}
    \ides{Binary Robust Independent Elementary Features (BRIEF) Descriptor:}
        \begin{itemize}
            \item Detect blobs
                \begin{itemize*}
                    \item[1)] ``Random'' (predefined) selection of pixel pairs
                    \item[2)] Compare intensity of pairs and store result in descriptor
                    \item[3)] Matching done with Hamming Distance
                \end{itemize*}
            \ipro High speed in description and matching
            \icon Not scale invariant
            \icon Not rotation invariant
        \end{itemize}
    \ides{Binary Robust Invariant Scalable Keypoints (BRISK) Detector}
        \begin{itemize*}
            \item Detect blobs
            \item[1)] Detect corners using FAST
            \item[2)] Compare intensity similar to BRIEF but in some specific geometric pattern
            \ipro High speed
            \ipro Rotation and scale invariant
            \icon Slower than BRIEF
        \end{itemize*}
\end{itemize}
